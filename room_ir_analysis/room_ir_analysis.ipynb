{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wavio\n",
    "from scipy import fftpack, signal\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "during the initialization stage of nlms filter, we should set each weight of FIR taps into a random value in order to seek a convergence result from iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlms(un, dn, M, mu):\n",
    "    \"\"\"\n",
    "    :param un: unknow signal\n",
    "    :type  un: numpy.ndarray\n",
    "    :param dn: expectation signal\n",
    "    :type  dn: numpy.ndarray\n",
    "    :param M : length of FIR filter\n",
    "    :type  M : int\n",
    "    :param mu: learning rate\n",
    "    :type  mu: float\n",
    "    :return: yn, en\n",
    "    \"\"\"\n",
    "    # To ensure the length of un and dn is same\n",
    "    ITER = min(len(un),len(dn)) \n",
    "    \n",
    "    # Signal buffer\n",
    "    u = np.zeros(M)\n",
    "    \n",
    "    # FIR Weights\n",
    "    w = np.random.normal(0, 0.4, M)\n",
    "    \n",
    "    # Estimated Signal, FIR Product\n",
    "    yn = np.zeros(ITER) \n",
    "    \n",
    "    # Error Signal, difference between estimation and expectation\n",
    "    en = np.zeros(ITER) \n",
    "    \n",
    "    for n in range(ITER):\n",
    "        u[1:M] = u[0:M-1]\n",
    "        u[0] = un[n]\n",
    "        yn[n] = np.dot(w.T, u)\n",
    "        en[n] = dn[n] - yn[n]\n",
    "        w = w + mu * en[n] * u / (np.dot(u, u) + 1e-7)\n",
    "    return yn, en, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = wavio.read(\"white_noise.wav\")\n",
    "white = white.data[:, 0]\n",
    "white = white.astype(np.float32, order='C') / 32767.0\n",
    "\n",
    "tele = wavio.read(\"tele_noise.wav\")\n",
    "tele = tele.data[:, 0]\n",
    "tele = tele.astype(np.float32, order='C') / 32767.0\n",
    "delay = 256\n",
    "tele = np.append(np.zeros(delay), tele)[:-delay]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White noise is generated by Audacity, amplitude in 0.8, after a telephone EQ curve applied whic reuslt in tele noise. We can use a optimal nlms(without interference - $v(n) = 0$, learning rate - $mu$ can be set into $1$) to observe the convergence weight of FIR taps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIR taps length\n",
    "M = 8192\n",
    "# moving steps, learning rate\n",
    "mu = 1\n",
    "\n",
    "xn = white\n",
    "dn = tele\n",
    "\n",
    "(yn, en, w) = nlms(xn, dn, M, mu)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(dn,label=\"$dn$\")\n",
    "plt.plot(xn,label=\"$xn$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"original signal xn and desired signal dn\")\n",
    "plt.legend() \n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(yn,label=\"$yn$\")\n",
    "plt.plot(xn,label=\"$xn$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"original signal xn and processing signal yn\")\n",
    "plt.legend()\n",
    "    \n",
    "plt.figure(3)\n",
    "plt.plot(en,label=\"$en$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"error between processing signal yn and desired voltage dn\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "weight = w\n",
    "\n",
    "x_axis = np.arange(len(weight))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.suptitle('Room Impulse Response Signal')\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(x_axis, weight, 'g--')\n",
    "plt.ylabel('left channel', color='g')\n",
    "plt.grid()\n",
    "\n",
    "weight_time = np.arange(len(weight))*1.0/sr\n",
    "weight_power = 20*np.log10(np.abs(np.fft.rfft(weight)))\n",
    "weight_frequency = np.linspace(0, sr/2.0, len(weight_power))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(weight_frequency, weight_power, 'b--')\n",
    "plt.ylabel(\"Power(dB)\")\n",
    "plt.xlabel(r'time(sample)')\n",
    "plt.xscale('log')\n",
    "plt.ylim(-120, 30)\n",
    "plt.xlim(20, 22000)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move previous experiment a step forward, apply a IIR biquad filter to white noise, we can convert this product back to frequency response(stable FIR coefficient) by nlms algorithm.\n",
    "\n",
    "- filter type = low-pass2\n",
    "- fc = 1500\n",
    "- fs = 44100\n",
    "- Q = 0.5\n",
    "- magnitude = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = [0.009384613070353884, 0.01876922614070777, 0.009384613070353884]\n",
    "denominator = [1.0, -1.6125031495280742, 0.6500416018094897]\n",
    "low_pass_output = signal.lfilter(numerator, denominator, white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIR taps length\n",
    "M = 1024\n",
    "# moving steps, learning rate\n",
    "mu = 1\n",
    "\n",
    "xn = white\n",
    "dn = low_pass_output\n",
    "\n",
    "(yn, en, w) = nlms(xn, dn, M, mu)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(dn,label=\"$dn$\")\n",
    "plt.plot(xn,label=\"$xn$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"original signal xn and desired signal dn\")\n",
    "plt.legend() \n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(yn,label=\"$yn$\")\n",
    "plt.plot(xn,label=\"$xn$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"original signal xn and processing signal yn\")\n",
    "plt.legend()\n",
    "    \n",
    "plt.figure(3)\n",
    "plt.plot(en,label=\"$en$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"error between processing signal yn and desired voltage dn\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "weight = w\n",
    "\n",
    "x_axis = np.arange(len(weight))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.suptitle('Room Impulse Response Signal')\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(x_axis, weight, 'g--')\n",
    "plt.ylabel('left channel', color='g')\n",
    "plt.grid()\n",
    "\n",
    "weight_time = np.arange(len(weight))*1.0/sr\n",
    "weight_power = 20*np.log10(np.abs(np.fft.rfft(weight)))\n",
    "weight_frequency = np.linspace(0, sr/2.0, len(weight_power))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(weight_frequency, weight_power, 'b--')\n",
    "plt.ylabel(\"Power(dB)\")\n",
    "plt.xlabel(r'time(sample)')\n",
    "plt.xscale('log')\n",
    "plt.ylim(-120, 30)\n",
    "plt.xlim(20, 22000)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "\n",
    "wav = wavio.read(\"large_choir_hall.wav\")\n",
    "\n",
    "left_channel = wav.data[:, 0]\n",
    "left_channel = left_channel.astype(np.float32, order='C') / 32767.0\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(8, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "plt.subplot(511)\n",
    "plt.plot(left_channel, 'r--')\n",
    "\n",
    "# using rfft to generate frequency response and phase response\n",
    "left_time = np.arange(len(left_channel))*1.0/sr\n",
    "left_magnitude = 20*np.log10(np.abs(np.fft.rfft(left_channel)))\n",
    "left_phase = np.angle(np.fft.rfft(left_channel))\n",
    "\n",
    "plt.subplot(512)\n",
    "plt.plot(left_magnitude, 'g')\n",
    "\n",
    "plt.subplot(513)\n",
    "plt.plot(left_phase, 'b--')\n",
    "\n",
    "# using freqz to generate frequency response and phase response\n",
    "w, h = signal.freqz(left_channel)\n",
    "amplitude = 20 * np.log10(abs(h))\n",
    "angle = np.angle(h)\n",
    "\n",
    "plt.subplot(514)\n",
    "plt.plot(w/max(w), amplitude, 'g')\n",
    "\n",
    "plt.subplot(515)\n",
    "plt.plot(w/max(w), angle, 'b--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_output = signal.convolve(in1=white, in2=left_channel, mode='same', method='fft') / sum(left_channel)\n",
    "plt.plot(convolution_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIR taps length\n",
    "M = 8192\n",
    "# moving steps, learning rate\n",
    "mu = 1\n",
    "\n",
    "xn = white\n",
    "dn = convolution_output\n",
    "\n",
    "(yn, en, w) = nlms(xn, dn, M, mu)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(dn,label=\"$dn$\")\n",
    "plt.plot(xn,label=\"$xn$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"original signal xn and desired signal dn\")\n",
    "plt.legend() \n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(yn,label=\"$yn$\")\n",
    "plt.plot(xn,label=\"$xn$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"original signal xn and processing signal yn\")\n",
    "plt.legend()\n",
    "    \n",
    "plt.figure(3)\n",
    "plt.plot(en,label=\"$en$\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.title(\"error between processing signal yn and desired voltage dn\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "weight = w\n",
    "\n",
    "x_axis = np.arange(len(weight))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.suptitle('Room Impulse Response Signal')\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(x_axis, weight, 'g--')\n",
    "plt.ylabel('left channel', color='g')\n",
    "plt.grid()\n",
    "\n",
    "weight_time = np.arange(len(weight))*1.0/sr\n",
    "weight_power = 20*np.log10(np.abs(np.fft.rfft(weight)))\n",
    "weight_frequency = np.linspace(0, sr/2.0, len(weight_power))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(weight_frequency, weight_power, 'b--')\n",
    "plt.ylabel(\"Power(dB)\")\n",
    "plt.xlabel(r'time(sample)')\n",
    "plt.xscale('log')\n",
    "plt.ylim(-120, 30)\n",
    "plt.xlim(20, 22000)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
